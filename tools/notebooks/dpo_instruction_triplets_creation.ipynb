{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Example output dataset: https://huggingface.co/datasets/mlabonne/llmtwin-dpo\n",
    "\n",
    "import concurrent.futures\n",
    "import json\n",
    "import re\n",
    "from typing import List, Tuple\n",
    "from datasets import Dataset\n",
    "from openai import OpenAI\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class PreferenceSet:\n",
    "    def __init__(self, triples: List[Tuple[str, str, str]]):\n",
    "        self.triples = triples\n",
    "    @classmethod\n",
    "    def from_json(cls, json_str: str) -> 'PreferenceSet':\n",
    "        data = json.loads(json_str)\n",
    "        triples = [(triple['instruction'], triple['generated_answer'], triple['extracted_answer'])\n",
    "                   for triple in data['preference_triples']]\n",
    "        return cls(triples)\n",
    "    def __iter__(self):\n",
    "        return iter(self.triples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def load_articles_from_json(file_path: str) -> Dataset:\n",
    "    with open(file_path, \"r\") as file:\n",
    "        data = json.load(file)\n",
    "    return Dataset.from_dict(\n",
    "        {\n",
    "            \"id\": [item[\"id\"] for item in data[\"artifact_data\"]],\n",
    "            \"content\": [item[\"content\"] for item in data[\"artifact_data\"]],\n",
    "            \"platform\": [item[\"platform\"] for item in data[\"artifact_data\"]],\n",
    "            \"author_id\": [item[\"author_id\"] for item in data[\"artifact_data\"]],\n",
    "            \"author_full_name\": [item[\"author_full_name\"] for item in data[\"artifact_data\"]],\n",
    "            \"link\": [item[\"link\"] for item in data[\"artifact_data\"]],\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def clean_text(text: str) -> str:    text = re.sub(r\"[^\\w\\s.,!?']\", \" \", text)    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def extract_substrings(dataset: Dataset, min_length: int = 1000, max_length: int = 2000) -> List[str]:\n",
    "    extracts = []\n",
    "    sentence_pattern = r\"(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?|\\!)\\s\"\n",
    "    for article in dataset[\"content\"]:\n",
    "        cleaned_article = clean_text(article)\n",
    "        sentences = re.split(sentence_pattern, cleaned_article)\n",
    "        current_chunk = \"\"\n",
    "        for sentence in sentences:\n",
    "            sentence = sentence.strip()\n",
    "            if not sentence:\n",
    "                continue\n",
    "            if len(current_chunk) + len(sentence) <= max_length:\n",
    "                current_chunk += sentence + \" \"\n",
    "            else:\n",
    "                if len(current_chunk) >= min_length:\n",
    "                    extracts.append(current_chunk.strip())\n",
    "                current_chunk = sentence + \" \"\n",
    "        if len(current_chunk) >= min_length:\n",
    "            extracts.append(current_chunk.strip())\n",
    "    return extracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def generate_preference_triples(extract: str, client: OpenAI) -> List[Tuple[str, str, str]]:\n",
    "    prompt = f\"\"\"Based on the following extract, generate five instruction-answer triples. Each triple should consist of:\n",
    "1. An instruction asking about a specific topic in the context.\n",
    "2. A generated answer that attempts to answer the instruction based on the context.\n",
    "3. An extracted answer that is a relevant excerpt directly from the given context.\n",
    "Instructions must be self-contained and general, without explicitly mentioning a context, system, course, or extract.\n",
    "Important:\n",
    "- Ensure that the extracted answer is a verbatim copy from the context, including all punctuation and apostrophes.\n",
    "- Do not add any ellipsis (...) or [...]  to indicate skipped text in the extracted answer.\n",
    "- If the relevant text is not continuous, use two separate sentences from the context instead of skipping text.\n",
    "Provide your response in JSON format with the following structure:\n",
    "{{\n",
    "    \"preference_triples\": [\n",
    "        {{\n",
    "            \"instruction\": \"...\",\n",
    "            \"generated_answer\": \"...\",\n",
    "            \"extracted_answer\": \"...\"\n",
    "        }},\n",
    "        ...\n",
    "    ]\n",
    "}}\n",
    "    Extract:\n",
    "    {extract}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful assistant who generates instruction-answer triples based on the given context. Each triple should include an instruction, a generated answer, and an extracted answer from the context. Provide your response in JSON format.\",\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "        max_tokens=2000,\n",
    "        temperature=0.7,\n",
    "    )\n",
    "    result = PreferenceSet.from_json(completion.choices[0].message.content)\n",
    "    return result.triples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def filter_short_answers(dataset: Dataset, min_length: int = 100) -> Dataset:\n",
    "    def is_long_enough(example):\n",
    "        return len(example['chosen']) >= min_length\n",
    "    return dataset.filter(is_long_enough)\n",
    "def filter_answer_format(dataset: Dataset) -> Dataset:\n",
    "    def is_valid_format(example):\n",
    "        chosen = example['chosen']\n",
    "        return (len(chosen) > 0 and\n",
    "                chosen[0].isupper() and\n",
    "                chosen[-1] in ('.', '!', '?'))\n",
    "    return dataset.filter(is_valid_format)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def create_preference_dataset(dataset: Dataset, client: OpenAI, num_workers: int = 4) -> Dataset:\n",
    "    extracts = extract_substrings(dataset)\n",
    "    preference_triples = []\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "        futures = [\n",
    "            executor.submit(generate_preference_triples, extract, client)\n",
    "            for extract in extracts\n",
    "        ]\n",
    "        for future in tqdm(concurrent.futures.as_completed(futures), total=len(futures)):\n",
    "            preference_triples.extend(future.result())\n",
    "    instructions, generated_answers, extracted_answers = zip(*preference_triples)\n",
    "    return Dataset.from_dict(\n",
    "        {\n",
    "            \"prompt\": list(instructions),\n",
    "            \"rejected\": list(generated_answers),\n",
    "            \"chosen\": list(extracted_answers)\n",
    "        }\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def main(dataset_id: str) -> Dataset:\n",
    "    client = OpenAI()\n",
    "    # 1. Load the raw data\n",
    "    raw_dataset = load_articles_from_json(\"cleaned_documents.json\")\n",
    "    print(\"Raw dataset:\")\n",
    "    print(raw_dataset.to_pandas())\n",
    "    # 2. Create preference dataset\n",
    "    dataset = create_preference_dataset(raw_dataset, client)\n",
    "    print(\"Preference dataset:\")\n",
    "    print(dataset.to_pandas())\n",
    "    # 3. Filter out samples with short answers\n",
    "    dataset = filter_short_answers(dataset)\n",
    "    # 4. Filter answers based on format\n",
    "    dataset = filter_answer_format(dataset)\n",
    "    # 5. Export\n",
    "    dataset.push_to_hub(dataset_id)\n",
    "    return dataset\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
